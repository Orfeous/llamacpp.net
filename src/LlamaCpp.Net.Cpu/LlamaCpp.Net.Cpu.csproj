<Project Sdk="Microsoft.NET.Sdk">

	<!-- Library -->
	<PropertyGroup>
		<TargetFrameworks>netstandard2.1;net6.0</TargetFrameworks>
		<Nullable>enable</Nullable>
		<ErrorReport>none</ErrorReport>
		<DebugType>embedded</DebugType>
		<CheckForOverflowUnderflow>True</CheckForOverflowUnderflow>
		<GenerateDocumentationFile>True</GenerateDocumentationFile>
		<ProduceReferenceAssembly>True</ProduceReferenceAssembly>
		<GeneratePackageOnBuild>True</GeneratePackageOnBuild>
		<AnalysisLevel>latest-recommended</AnalysisLevel>
	</PropertyGroup>
	<!-- /Library -->

	<!-- Version -->
	<PropertyGroup>
		<Version>0.0.1</Version>
		<PackageVersion>$(Version)-alpha</PackageVersion>
		<AssemblyVersion>$(Version).0</AssemblyVersion>
		<FileVersion>$(Version).0</FileVersion>
	</PropertyGroup>
	<!-- /Version -->

	<!-- Package -->
	<PropertyGroup>
		<Title>LlamaCpp.Net.Cpu</Title>
		<Description>C#/.NET binding of llama.cpp - CPU inference library</Description>
		<Authors>orfeous, mlof</Authors>
		<Copyright>2023 - orfeous, mlof</Copyright>
		<PackageTags>LLama, LLM, AI,</PackageTags>
		<ApplicationIcon>llama-glyph-256.ico</ApplicationIcon>
		<PackageIcon>llama-glyph-128.png</PackageIcon>
		<PackageProjectUrl>https://github.com/Orfeous/llamacpp.net</PackageProjectUrl>
		<RepositoryUrl>https://github.com/Orfeous/llamacpp.net.git</RepositoryUrl>
		<RepositoryType>git</RepositoryType>
		<PackageReadmeFile>readme.md</PackageReadmeFile>
		<PackageLicenseFile>LICENSE</PackageLicenseFile>
	</PropertyGroup>

	<ItemGroup>
		<Content Include="llama-glyph-256.ico" />
		<None Include="..\..\assets\llama-glyph-128.png">
			<Pack>True</Pack>
			<PackagePath>\</PackagePath>
		</None>
		<None Include="..\..\LICENSE">
			<Pack>True</Pack>
			<PackagePath>\</PackagePath>
		</None>
		<None Include="..\..\readme.md">
			<Pack>True</Pack>
			<PackagePath>\</PackagePath>
		</None>
	</ItemGroup>

	<PropertyGroup Condition="'$(Configuration)|$(TargetFramework)|$(Platform)'=='Debug|netstandard2.1|AnyCPU'">
		<DebugType>embedded</DebugType>
		<WarningLevel>4</WarningLevel>
		<CheckForOverflowUnderflow>True</CheckForOverflowUnderflow>
	</PropertyGroup>

	<PropertyGroup Condition="'$(Configuration)|$(TargetFramework)|$(Platform)'=='Debug|net6.0|AnyCPU'">
		<DebugType>embedded</DebugType>
		<CheckForOverflowUnderflow>True</CheckForOverflowUnderflow>
	</PropertyGroup>

	<PropertyGroup Condition="'$(Configuration)|$(TargetFramework)|$(Platform)'=='Release|netstandard2.1|AnyCPU'">
		<DebugType>embedded</DebugType>
		<WarningLevel>4</WarningLevel>
		<CheckForOverflowUnderflow>True</CheckForOverflowUnderflow>
	</PropertyGroup>

	<PropertyGroup Condition="'$(Configuration)|$(TargetFramework)|$(Platform)'=='Release|net6.0|AnyCPU'">
		<DebugType>embedded</DebugType>
		<CheckForOverflowUnderflow>True</CheckForOverflowUnderflow>
	</PropertyGroup>
	<!-- /Package -->

	<ItemGroup>
		<ProjectReference Include="..\LlamaCpp.Net\LlamaCpp.Net.csproj" />
	</ItemGroup>

	<ItemGroup>
	  <None Update="llama.dll">
	    <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
	  </None>
	</ItemGroup>

</Project>
